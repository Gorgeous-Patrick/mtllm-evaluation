{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'results'\n",
    "EVAL_CONFIG = 'eval.config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(EVAL_CONFIG) as f:\n",
    "    eval_config = json.load(f)\n",
    "\n",
    "problem_set = {}\n",
    "for difficulty in eval_config.keys():\n",
    "    if difficulty not in problem_set:\n",
    "        problem_set[difficulty] = []\n",
    "    for problem in eval_config[difficulty].keys():\n",
    "        problem_set[difficulty].append(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EASY': ['translation',\n",
       "  'essay_reviewer',\n",
       "  'joke_gen',\n",
       "  'expert_answer',\n",
       "  'odd_word_out'],\n",
       " 'MEDIUM': ['mcq_reason', 'personality_finder', 'template', 'text_to_type'],\n",
       " 'HARD': ['rpg_level_gen', 'wikipedia']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_DIFFICULTY = 'EASY' # 'EASY', 'MEDIUM', 'HARD'\n",
    "\n",
    "def get_results(difficulty):\n",
    "    results = {}\n",
    "    for problem in problem_set[difficulty]:\n",
    "        results[problem] = get_problem_results(problem)\n",
    "    return results\n",
    "\n",
    "def get_problem_results(problem):\n",
    "    '''Input prompt, Output prompt, Token Usage, Output'''\n",
    "    return {\n",
    "        \"jac\": get_problem_result(problem, \"jac\"),\n",
    "        \"dspy\": get_problem_result(problem, \"dspy\"),\n",
    "    }\n",
    "\n",
    "def get_problem_result(problem, impl=\"jac\"):\n",
    "    _output = {\n",
    "        \"llm_requests\": [],\n",
    "        \"output\": \"\"\n",
    "    }\n",
    "    \n",
    "    file = f\"{RESULTS_DIR}/{problem}/{impl}/results.txt\"\n",
    "    with open(file) as f:\n",
    "        file_contents = f.read()\n",
    "    \n",
    "    while True:\n",
    "        input_prompt_pattern = r'Input Prompt:\\n(.*?)\\nOutput:'\n",
    "        input_prompt_match = re.search(input_prompt_pattern, file_contents, re.DOTALL)\n",
    "        if input_prompt_match:\n",
    "            input_prompt = input_prompt_match.group(1).strip()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        output_pattern = r'Output:\\n(.*?)\\n\\{' if impl == \"dspy\" else r'Output:\\n(.*?)\\nCompletionUsage'\n",
    "        output_match = re.search(output_pattern, file_contents, re.DOTALL)\n",
    "        if output_match:\n",
    "            output = output_match.group(1).strip()\n",
    "\n",
    "        file_contents = file_contents[output_match.end():]\n",
    "        if impl == \"dspy\":\n",
    "            slide = 0\n",
    "            token_pattern = r\"'completion_tokens': (\\d+), 'prompt_tokens': (\\d+), 'total_tokens': (\\d+)}\\n\"\n",
    "        else:\n",
    "            slide = 1\n",
    "            token_pattern = r\"(completion_tokens=(\\d+), prompt_tokens=(\\d+), total_tokens=(\\d+))\"\n",
    "        token_match = re.search(token_pattern, file_contents)\n",
    "        if token_match:\n",
    "            completion_tokens = int(token_match.group(1+slide))\n",
    "            prompt_tokens = int(token_match.group(2+slide))\n",
    "            total_tokens = int(token_match.group(3+slide))\n",
    "\n",
    "        file_contents = file_contents[token_match.end():]\n",
    "\n",
    "        _output[\"llm_requests\"].append({\n",
    "            \"prompt\": input_prompt,\n",
    "            \"output\": output,\n",
    "            \"token_usage\": {\n",
    "                \"completion_tokens\": completion_tokens,\n",
    "                \"prompt_tokens\": prompt_tokens,\n",
    "                \"total_tokens\": total_tokens,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    _output[\"output\"] = file_contents.strip()\n",
    "    return _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for difficulty in problem_set.keys():\n",
    "    _results = get_results(difficulty)\n",
    "    with open(f\"{RESULTS_DIR}/{difficulty}.json\", \"w\") as f:\n",
    "        json.dump(_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Token Usage and Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(difficulty):\n",
    "    with open(f\"{RESULTS_DIR}/{difficulty}.json\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results = load_results('EASY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_costs = {\n",
    "    \"completion_tokens\": 15/1e6,\n",
    "    \"prompt_tokens\":5/1e6,\n",
    "}\n",
    "\n",
    "def get_results_df(results):\n",
    "    rows = []\n",
    "    for problem, result in results.items():\n",
    "        jac = result[\"jac\"]\n",
    "        dspy = result[\"dspy\"]\n",
    "        rows.append({\n",
    "            \"problem\": problem,\n",
    "            \"jac_completion_tokens\": sum([llm[\"token_usage\"][\"completion_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"jac_prompt_tokens\": sum([llm[\"token_usage\"][\"prompt_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"jac_total_tokens\": sum([llm[\"token_usage\"][\"total_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"dspy_completion_tokens\": sum([llm[\"token_usage\"][\"completion_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"dspy_prompt_tokens\": sum([llm[\"token_usage\"][\"prompt_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"dspy_total_tokens\": sum([llm[\"token_usage\"][\"total_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"jac_cost\": sum([llm[\"token_usage\"][\"completion_tokens\"]*llm_costs[\"completion_tokens\"] + llm[\"token_usage\"][\"prompt_tokens\"]*llm_costs[\"prompt_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"dspy_cost\": sum([llm[\"token_usage\"][\"completion_tokens\"]*llm_costs[\"completion_tokens\"] + llm[\"token_usage\"][\"prompt_tokens\"]*llm_costs[\"prompt_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@kugesan will add graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Taken Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xfb in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_prof_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/essay_reviewer/dspy/profile.prof\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[137], line 7\u001b[0m, in \u001b[0;36mload_prof_file\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_prof_file\u001b[39m(file):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# read the contents of the file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m         profile \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# split the contents by newline\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     profile \u001b[38;5;241m=\u001b[39m profile\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xfb in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "load_prof_file('results/essay_reviewer/dspy/profile.prof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtllm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
