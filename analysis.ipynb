{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'results'\n",
    "EVAL_CONFIG = 'eval.config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(EVAL_CONFIG) as f:\n",
    "    eval_config = json.load(f)\n",
    "\n",
    "problem_set = {}\n",
    "for difficulty in eval_config.keys():\n",
    "    if difficulty not in problem_set:\n",
    "        problem_set[difficulty] = []\n",
    "    for problem in eval_config[difficulty].keys():\n",
    "        problem_set[difficulty].append(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EASY': ['translation',\n",
       "  'essay_reviewer',\n",
       "  'joke_gen',\n",
       "  'expert_answer',\n",
       "  'odd_word_out'],\n",
       " 'MEDIUM': ['mcq_reason', 'personality_finder', 'template', 'text_to_type'],\n",
       " 'HARD': ['rpg_level_gen', 'wikipedia']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_DIFFICULTY = 'EASY' # 'EASY', 'MEDIUM', 'HARD'\n",
    "\n",
    "def get_results(difficulty):\n",
    "    results = {}\n",
    "    for problem in problem_set[difficulty]:\n",
    "        results[problem] = get_problem_results(problem)\n",
    "    return results\n",
    "\n",
    "def get_problem_results(problem):\n",
    "    '''Input prompt, Output prompt, Token Usage, Output'''\n",
    "    return {\n",
    "        \"jac\": get_problem_result(problem, \"jac\"),\n",
    "        \"dspy\": get_problem_result(problem, \"dspy\"),\n",
    "    }\n",
    "\n",
    "def get_problem_result(problem, impl=\"jac\"):\n",
    "    _output = {\n",
    "        \"llm_requests\": [],\n",
    "        \"output\": \"\"\n",
    "    }\n",
    "    \n",
    "    file = f\"{RESULTS_DIR}/{problem}/{impl}/results.txt\"\n",
    "    with open(file) as f:\n",
    "        file_contents = f.read()\n",
    "    \n",
    "    while True:\n",
    "        input_prompt_pattern = r'Input Prompt:\\n(.*?)\\nOutput:'\n",
    "        input_prompt_match = re.search(input_prompt_pattern, file_contents, re.DOTALL)\n",
    "        if input_prompt_match:\n",
    "            input_prompt = input_prompt_match.group(1).strip()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        output_pattern = r'Output:\\n(.*?)\\n\\{' if impl == \"dspy\" else r'Output:\\n(.*?)\\nCompletionUsage'\n",
    "        output_match = re.search(output_pattern, file_contents, re.DOTALL)\n",
    "        if output_match:\n",
    "            output = output_match.group(1).strip()\n",
    "\n",
    "        file_contents = file_contents[output_match.end():]\n",
    "        if impl == \"dspy\":\n",
    "            slide = 0\n",
    "            token_pattern = r\"'completion_tokens': (\\d+), 'prompt_tokens': (\\d+), 'total_tokens': (\\d+)}\\n\"\n",
    "        else:\n",
    "            slide = 1\n",
    "            token_pattern = r\"(completion_tokens=(\\d+), prompt_tokens=(\\d+), total_tokens=(\\d+))\"\n",
    "        token_match = re.search(token_pattern, file_contents)\n",
    "        if token_match:\n",
    "            completion_tokens = int(token_match.group(1+slide))\n",
    "            prompt_tokens = int(token_match.group(2+slide))\n",
    "            total_tokens = int(token_match.group(3+slide))\n",
    "\n",
    "        file_contents = file_contents[token_match.end():]\n",
    "\n",
    "        _output[\"llm_requests\"].append({\n",
    "            \"prompt\": input_prompt,\n",
    "            \"output\": output,\n",
    "            \"token_usage\": {\n",
    "                \"completion_tokens\": completion_tokens,\n",
    "                \"prompt_tokens\": prompt_tokens,\n",
    "                \"total_tokens\": total_tokens,\n",
    "            }\n",
    "        })\n",
    "\n",
    "    _output[\"output\"] = file_contents.strip()\n",
    "    return _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for difficulty in problem_set.keys():\n",
    "    _results = get_results(difficulty)\n",
    "    with open(f\"{RESULTS_DIR}/{difficulty}.json\", \"w\") as f:\n",
    "        json.dump(_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Token Usage and Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(difficulty):\n",
    "    with open(f\"{RESULTS_DIR}/{difficulty}.json\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results = load_results('EASY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_costs = {\n",
    "    \"completion_tokens\": 15/1e6,\n",
    "    \"prompt_tokens\":5/1e6,\n",
    "}\n",
    "\n",
    "def get_results_df(results):\n",
    "    rows = []\n",
    "    for problem, result in results.items():\n",
    "        jac = result[\"jac\"]\n",
    "        dspy = result[\"dspy\"]\n",
    "        rows.append({\n",
    "            \"problem\": problem,\n",
    "            \"jac_completion_tokens\": sum([llm[\"token_usage\"][\"completion_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"jac_prompt_tokens\": sum([llm[\"token_usage\"][\"prompt_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"jac_total_tokens\": sum([llm[\"token_usage\"][\"total_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"dspy_completion_tokens\": sum([llm[\"token_usage\"][\"completion_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"dspy_prompt_tokens\": sum([llm[\"token_usage\"][\"prompt_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"dspy_total_tokens\": sum([llm[\"token_usage\"][\"total_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "            \"jac_cost\": sum([llm[\"token_usage\"][\"completion_tokens\"]*llm_costs[\"completion_tokens\"] + llm[\"token_usage\"][\"prompt_tokens\"]*llm_costs[\"prompt_tokens\"] for llm in jac[\"llm_requests\"]]),\n",
    "            \"dspy_cost\": sum([llm[\"token_usage\"][\"completion_tokens\"]*llm_costs[\"completion_tokens\"] + llm[\"token_usage\"][\"prompt_tokens\"]*llm_costs[\"prompt_tokens\"] for llm in dspy[\"llm_requests\"]]),\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@kugesan will add graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Taken Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "\n",
    "def get_time(problem, impl):\n",
    "    p_dspy = pstats.Stats(f'results/{problem}/{impl}/profile.prof')\n",
    "    total_time = p_dspy.total_tt\n",
    "    llm_time = p_dspy.sort_stats('cumulative').stats[('/opt/conda/envs/mtllm-eval/lib/python3.12/site-packages/openai/_utils/_utils.py', 243, 'wrapper')][3]\n",
    "    return total_time, llm_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_with_time = results_df.copy()\n",
    "results_df_with_time['jac_total_time'] = results_df_with_time['problem'].apply(lambda x: get_time(x, 'jac')[0])\n",
    "results_df_with_time['jac_llm_time'] = results_df_with_time['problem'].apply(lambda x: get_time(x, 'jac')[1])\n",
    "results_df_with_time['dspy_total_time'] = results_df_with_time['problem'].apply(lambda x: get_time(x, 'dspy')[0])\n",
    "results_df_with_time['dspy_llm_time'] = results_df_with_time['problem'].apply(lambda x: get_time(x, 'dspy')[1])\n",
    "results_df_with_time[\"jac_runtime\"] = results_df_with_time[\"jac_total_time\"] - results_df_with_time[\"jac_llm_time\"]\n",
    "results_df_with_time[\"dspy_runtime\"] = results_df_with_time[\"dspy_total_time\"] - results_df_with_time[\"dspy_llm_time\"]\n",
    "results_df_with_time[\"jac_runtime_percent\"] = results_df_with_time[\"jac_runtime\"] / results_df_with_time[\"jac_total_time\"]\n",
    "results_df_with_time[\"dspy_runtime_percent\"] = results_df_with_time[\"dspy_runtime\"] / results_df_with_time[\"dspy_total_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>jac_completion_tokens</th>\n",
       "      <th>jac_prompt_tokens</th>\n",
       "      <th>jac_total_tokens</th>\n",
       "      <th>dspy_completion_tokens</th>\n",
       "      <th>dspy_prompt_tokens</th>\n",
       "      <th>dspy_total_tokens</th>\n",
       "      <th>jac_cost</th>\n",
       "      <th>dspy_cost</th>\n",
       "      <th>jac_total_time</th>\n",
       "      <th>jac_llm_time</th>\n",
       "      <th>dspy_total_time</th>\n",
       "      <th>dspy_llm_time</th>\n",
       "      <th>jac_runtime</th>\n",
       "      <th>dspy_runtime</th>\n",
       "      <th>jac_runtime_percent</th>\n",
       "      <th>dspy_runtime_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translation</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>182</td>\n",
       "      <td>54</td>\n",
       "      <td>320</td>\n",
       "      <td>374</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>1.701438</td>\n",
       "      <td>0.788278</td>\n",
       "      <td>7.607343</td>\n",
       "      <td>5.113171</td>\n",
       "      <td>0.913160</td>\n",
       "      <td>2.494172</td>\n",
       "      <td>0.536699</td>\n",
       "      <td>0.327864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essay_reviewer</td>\n",
       "      <td>267</td>\n",
       "      <td>1512</td>\n",
       "      <td>1779</td>\n",
       "      <td>750</td>\n",
       "      <td>1407</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>7.405499</td>\n",
       "      <td>6.968499</td>\n",
       "      <td>26.674179</td>\n",
       "      <td>22.303699</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>4.370480</td>\n",
       "      <td>0.059010</td>\n",
       "      <td>0.163847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joke_gen</td>\n",
       "      <td>19</td>\n",
       "      <td>176</td>\n",
       "      <td>195</td>\n",
       "      <td>59</td>\n",
       "      <td>191</td>\n",
       "      <td>250</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>1.300078</td>\n",
       "      <td>1.239698</td>\n",
       "      <td>2.800871</td>\n",
       "      <td>2.776441</td>\n",
       "      <td>0.060380</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.046444</td>\n",
       "      <td>0.008722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_answer</td>\n",
       "      <td>113</td>\n",
       "      <td>290</td>\n",
       "      <td>403</td>\n",
       "      <td>159</td>\n",
       "      <td>111</td>\n",
       "      <td>270</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>4.345821</td>\n",
       "      <td>4.022049</td>\n",
       "      <td>3.917878</td>\n",
       "      <td>3.908516</td>\n",
       "      <td>0.323772</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.074502</td>\n",
       "      <td>0.002390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odd_word_out</td>\n",
       "      <td>28</td>\n",
       "      <td>257</td>\n",
       "      <td>285</td>\n",
       "      <td>274</td>\n",
       "      <td>547</td>\n",
       "      <td>821</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>1.185508</td>\n",
       "      <td>1.114505</td>\n",
       "      <td>9.897317</td>\n",
       "      <td>7.919308</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>1.978008</td>\n",
       "      <td>0.059892</td>\n",
       "      <td>0.199853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          problem  jac_completion_tokens  jac_prompt_tokens  jac_total_tokens  \\\n",
       "0     translation                      4                178               182   \n",
       "1  essay_reviewer                    267               1512              1779   \n",
       "2        joke_gen                     19                176               195   \n",
       "3   expert_answer                    113                290               403   \n",
       "4    odd_word_out                     28                257               285   \n",
       "\n",
       "   dspy_completion_tokens  dspy_prompt_tokens  dspy_total_tokens  jac_cost  \\\n",
       "0                      54                 320                374  0.000950   \n",
       "1                     750                1407               2157  0.011565   \n",
       "2                      59                 191                250  0.001165   \n",
       "3                     159                 111                270  0.003145   \n",
       "4                     274                 547                821  0.001705   \n",
       "\n",
       "   dspy_cost  jac_total_time  jac_llm_time  dspy_total_time  dspy_llm_time  \\\n",
       "0   0.002410        1.701438      0.788278         7.607343       5.113171   \n",
       "1   0.018285        7.405499      6.968499        26.674179      22.303699   \n",
       "2   0.001840        1.300078      1.239698         2.800871       2.776441   \n",
       "3   0.002940        4.345821      4.022049         3.917878       3.908516   \n",
       "4   0.006845        1.185508      1.114505         9.897317       7.919308   \n",
       "\n",
       "   jac_runtime  dspy_runtime  jac_runtime_percent  dspy_runtime_percent  \n",
       "0     0.913160      2.494172             0.536699              0.327864  \n",
       "1     0.437000      4.370480             0.059010              0.163847  \n",
       "2     0.060380      0.024430             0.046444              0.008722  \n",
       "3     0.323772      0.009362             0.074502              0.002390  \n",
       "4     0.071003      1.978008             0.059892              0.199853  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtllm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
